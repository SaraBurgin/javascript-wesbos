const video = document.querySelector('.webcam');
const canvas = document.querySelector('.video');
const ctx = canvas.getContext('2d');
const faceCanvas = document.querySelector('.face');
const faceCtx = faceCanvas.getContext('2d');
const faceDetector = new window.FaceDetector(); // Write a function that will populate(show) the users video
// 1Â° What we have done is create the function and make it async because sometimes stream takes a while to start so it awaits for the camera to start and then loads the function
// with navigator.mediaDevices.getUserMedia() we grab the feed off the users webcam, then we set the object to be the stream and we went ahead and played it with await video.play();

async function populateVideo() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: {
      width: 1280,
      height: 720
    }
  });
  video.srcObject = stream;
  await video.play(); // Also await here because sometimes playing also takes a second or two and that will wait for it to start playing
  // size the canvases to be the same size as the video

  console.log(video.videoWidth, video.videoHeight);
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  faceCanvas.width = video.videoWidth;
  faceCanvas.height = video.videoHeight;
} // We want to detect faces that are in the shot


async function detect() {
  const faces = await faceDetector.detect(video);
  console.log(faces); // Ask the browser when the next animation frame is, and tell it to run detect for us. This below is called recursion, this happens when a function calls itself.

  requestAnimationFrame(detect);
}

populateVideo().then(detect);